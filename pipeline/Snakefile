"""
Author:  Karel Brinda <kbrinda@hsph.harvard.edu>

License: MIT
"""

import datetime
import glob
import os
import sys

snakemake.shell.prefix("set -eo pipefail;")

configfile: "config.yaml"

localrules: plot, plot_timeline, plot_snapshots, predict, preprocess_reads, all

#print(config)


# 1) Detect indexes

def remove_suffix(fn, suffix=None):
    if fn is None:
        return None
    if suffix is None:
        parts=fn.split(".")
        return ".".join(parts[:-1])
    else:
        if suffix[0]!=".":
            suffix="."+suffix
        l=len(suffix)
        pot_suffix=fn[-l:]
        assert pot_suffix==suffix
        return fn[:-l]


def file_size(fn):
    return os.stat(fn).st_size

def smallest_file(fns):
    size=10**30
    sfn=None
    for fn in fns:
        rfn=os.path.realpath(fn)
        if file_size(rfn)<size:
            size=file_size(rfn)
            sfn=fn
    return sfn

def find_db_files(suffix, smallest_only=False):
    fns=glob.glob("database/*.{}".format(suffix))
    if smallest_only:
        fns=[smallest_file(fns)]
    return [os.path.basename(fn).replace("."+suffix,"") for fn in fns]

indexes_base_tsv=find_db_files("tsv")

indexes_base_tar=find_db_files("tar.gz")
indexes=sorted(list(set(indexes_base_tsv) & set(indexes_base_tar)))

indexes_base_tar_smallest=find_db_files("tar.gz", smallest_only=True)
smallest_index=list(set(indexes_base_tsv) & set(indexes_base_tar_smallest))

#detection_failure=False
print("Indexes:", indexes)
if len(indexes)==0:
    print("!!!! ", file=sys.stderr)
    print("!!!! RASE PIPELINE ERROR ", file=sys.stderr)
    print("!!!! ", file=sys.stderr)
    print("!!!! No index provided ({db}.tsv and {db.tar.gz}).", file=sys.stderr)
    print("!!!! ", file=sys.stderr)
    #detection_failure=True


# 2) Detect reads

readfiles=glob.glob("reads/*."+config["reads_suffix"])
print("Detected read files:", readfiles)
if len(readfiles)==0:
    print("!!!! ", file=sys.stderr)
    print("!!!! RASE PIPELINE ERROR ", file=sys.stderr)
    print("!!!! ", file=sys.stderr)
    print("!!!! No files with sequencing reads provided (*.{}).".format(config["reads_suffix"]), file=sys.stderr)
    print("!!!! Adjust your config file if a different format is used.".format(config["reads_suffix"]), file=sys.stderr)
    print("!!!! ", file=sys.stderr)
    #detection_failure=True

#if detection_failure:
#    sys.exit(42)


# 3) Setup experiments

experiments=sorted([os.path.basename(remove_suffix(x, config["reads_suffix"])) for x in readfiles])
smallest_reads=smallest_file(readfiles)
if smallest_reads is not None:
    smallest_experiment=[os.path.basename(remove_suffix(smallest_reads, config["reads_suffix"]))]
else:
    smallest_experiment=[]
print("Experiments:", experiments)


# 4) Check whether all dependencies are installed

snakemake.shell("(../scripts/rase_test_environments.sh 2>&1) >/dev/null || ../scripts/rase_test_environments.sh")


localrules: test_environments

rule all:
    input:
        [
            [
                [
                    ancient(f"prediction/.{e}.read.complete"),
                    ancient(f"prediction/.{e}__{i}.assign.complete"),
                    ancient(f"prediction/.{e}__{i}.predict.complete"),
                    ancient(f"plots/.{e}__{i}.plot.complete"),
                ]
                for i in indexes
            ]
            for e in experiments
        ],

rule database:
	input:
		[ancient(f"database/.{index}.complete") for index in indexes]


rule test:
    input:
        [
            [
                [
                    ancient(f"prediction/.{e}.read.complete"),
                    ancient(f"prediction/.{e}__{i}.bam.complete"),
                    ancient(f"prediction/.{e}__{i}.predict.complete"),
                    ancient(f"plots/.{e}__{i}.plot.complete"),
                ]
                for i in smallest_index
            ]
            for e in smallest_experiment
        ],


rule preprocess_reads:
    input:
        reads=ancient("reads/{pref}."+config["reads_suffix"]),
    output:
        t="prediction/.{pref}.read.complete"
    params:
        reads="prediction/{pref}."+config["reads_suffix"]
    benchmark:
        "benchmarks/{pref}.readprep.log"
    shell:
        """
            ../src/rase/rase_minion_rename_reads.py "{input.reads}" \
                | paste -d '\t' - - - - \
                | sort \
                | uniq \
                | perl -pe 's/\t/\n/g' \
                > "{params.reads}"
            touch "{output.t}"
        """ if config["time_mode"] =="read" else """
            cp "{input.reads}" "{params.reads}"
            touch "{output.t}"
        """


rule assign:
    priority: 60
    input:
        ancient("database/.{index}.complete"),
        ancient("prediction/.{pref}.read.complete"),
    output:
        t="prediction/.{pref}__{index}.assign.complete",
    params:
        reads="prediction/{pref}."+config["reads_suffix"],
        bam="prediction/{pref}__{index}.bam",
        index="database/{index}"
    benchmark:
        "benchmarks/{pref}__{index}.classify.log"
    shell:
        """
            prophyle classify -P "{params.index}" -m h1 "{params.reads}" \
                | samtools view -b \
                > "{params.bam}"
            touch "{output.t}"
        """



rule predict:
    priority: 80
    input:
        ancient("prediction/.{pref}__{index}.assign.complete"),
        ancient("database/.{index}.complete"),
    output:
        t="prediction/.{pref}__{index}.predict.complete",
    params:
        bam="prediction/{pref}__{index}.bam",
        snapshot_dir="prediction/{pref}__{index}/",
        tree="database/{index}/tree.nw",
        metadata="database/{index}.tsv",
        tsv1="prediction/{pref}__{index}.predict_without_flags.tsv",
        tsv2="prediction/{pref}__{index}.predict.tsv",
    benchmark:
        "benchmarks/{pref}__{index}.predict.log"
    shell:
        """
            mkdir -p "prediction/{wildcards.pref}__{wildcards.index}"
            ../src/rase/rase_predict.py -t {config[time_mode]} -s {config[prediction_sampling]} -p "{params.snapshot_dir}" "{params.tree}" "{params.metadata}" "{params.bam}" \
                > "{params.tsv1}"
            ../src/rase/rase_prediction_add_flags.py  "{params.tsv1}" \
                > "{params.tsv2}"
            rm "{params.tsv1}"
            touch "{output.t}"
        """


rule plot:
    output:
        t="plots/.{pref}__{index}.plot.complete",
    input:
        t1=ancient("plots/.{pref}__{index}.plot_timeline.complete"),
        t2=ancient("plots/.{pref}__{index}.plot_snapshots.complete"),
    shell:
        """
            touch "{output.t}"
        """

rule plot_timeline:
    priority: 90
    output:
        t="plots/.{pref}__{index}.plot_timeline.complete",
    input:
        ancient("prediction/.{pref}__{index}.predict.complete"),
        ancient("database/.{index}.complete"),
    benchmark:
        "benchmarks/{pref}__{index}.plot_timeline.log"
    params:
        tsv="prediction/{pref}__{index}.predict.tsv",
        pdf="plots/{pref}__{index}.timeline.pdf",
        index="database/{index}",
        pref="{pref}"
    shell:
        """
            ../scripts/rase_plot_timeline.R "{params.tsv}" "{params.pdf}"
            touch "{output.t}"
        """


rule plot_snapshots:
    priority: 90
    output:
        t="plots/.{pref}__{index}.plot_snapshots.complete",
    input:
        ancient("prediction/.{pref}__{index}.predict.complete"),
        ancient("database/.{index}.complete"),
    benchmark:
        "benchmarks/{pref}__{index}.plot_snapshots.log"
    params:
        tsv="prediction/{pref}__{index}.predict.tsv",
        index_tsv="database/{index}.tsv",
        pred_dir="prediction/{pref}__{index}",
        plots_pref="plots/{pref}__{index}.snapshots.",
    shell:
        """
            ../src/rase/rase_plot_selected_snapshots.py "{params.index_tsv}" "{params.pred_dir}" 1 5 -1 "{params.plots_pref}"
            touch "{output.t}"
        """


rule decompress:
    output:
        t="database/.{index}.complete"
    input:
        gz=ancient("database/{index}.tar.gz"),
        tsv=ancient("database/{index}.tsv"),
    benchmark:
        "benchmarks/decompress.{index}.log"
    shell:
        """
            mkdir -p "database/{wildcards.index}"
            prophyle decompress "{input.gz}" database
            touch "{output.t}"
        """

